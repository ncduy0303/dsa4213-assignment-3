Job is running on xgpi0, started at Thu Oct 16 08:41:41 PM +08 2025
Thu Oct 16 20:41:41 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 NVL                On  |   00000000:E3:00.0 Off |                    0 |
| N/A   57C    P0             88W /  400W |       0MiB /  95830MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Starting W&B agent for sweep: ncduy0303/dsa4213-assignment-3/2py1600r
10/16/2025 20:41:55 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 20:41:55 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_20-41-55_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 20:41:55 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/l4p88sqj
10/16/2025 20:41:59 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 20:41:59 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:41:59 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:42:00 - INFO - __main__ - setting problem type to single label classification
10/16/2025 20:42:01 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 20:42:01 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 20:42:01 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 20:42:01 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 20:42:01 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 20:42:02 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 20:42:02 - INFO - __main__ - Shuffling the training dataset
10/16/2025 20:42:02 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 20:42:02 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:42:02 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:42:02 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:42:04 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5826129913330078, 'eval_accuracy': 0.352, 'eval_runtime': 3.5264, 'eval_samples_per_second': 567.149, 'eval_steps_per_second': 70.894, 'epoch': 1.0}
{'loss': 1.6038, 'grad_norm': 2.0002031326293945, 'learning_rate': 1.2016000000000002e-05, 'epoch': 2.0}
{'eval_loss': 1.577350378036499, 'eval_accuracy': 0.352, 'eval_runtime': 3.5166, 'eval_samples_per_second': 568.735, 'eval_steps_per_second': 71.092, 'epoch': 2.0}
{'eval_loss': 1.5752700567245483, 'eval_accuracy': 0.352, 'eval_runtime': 3.521, 'eval_samples_per_second': 568.021, 'eval_steps_per_second': 71.003, 'epoch': 3.0}
{'loss': 1.5802, 'grad_norm': 1.0997809171676636, 'learning_rate': 4.016e-06, 'epoch': 4.0}
{'eval_loss': 1.5734434127807617, 'eval_accuracy': 0.352, 'eval_runtime': 3.5152, 'eval_samples_per_second': 568.957, 'eval_steps_per_second': 71.12, 'epoch': 4.0}
{'eval_loss': 1.5730074644088745, 'eval_accuracy': 0.352, 'eval_runtime': 3.5085, 'eval_samples_per_second': 570.045, 'eval_steps_per_second': 71.256, 'epoch': 5.0}
{'train_runtime': 235.8659, 'train_samples_per_second': 339.176, 'train_steps_per_second': 5.3, 'train_loss': 1.5893358154296875, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.5893
  train_runtime            = 0:03:55.86
  train_samples            =      16000
  train_samples_per_second =    339.176
  train_steps_per_second   =        5.3
10/16/2025 20:46:01 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.352
  eval_loss               =     1.5826
  eval_runtime            = 0:00:03.50
  eval_samples            =       2000
  eval_samples_per_second =    571.297
  eval_steps_per_second   =     71.412
10/16/2025 20:46:05 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.3475
  predict_loss               =     1.5638
  predict_runtime            = 0:00:03.49
  predict_samples            =       2000
  predict_samples_per_second =    572.166
  predict_steps_per_second   =     71.521
10/16/2025 20:46:08 - INFO - __main__ - ***** Predict results *****
10/16/2025 20:46:08 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/l4p88sqj/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mdeft-sweep-1[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/l4p88sqj[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_204205-l4p88sqj/logs[0m
10/16/2025 20:46:22 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 20:46:22 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_20-46-22_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 20:46:22 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/kocczfys
10/16/2025 20:46:26 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 20:46:26 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:46:26 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:46:26 - INFO - __main__ - setting problem type to single label classification
10/16/2025 20:46:27 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 20:46:27 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 20:46:27 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 20:46:27 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 20:46:27 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 20:46:28 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 20:46:28 - INFO - __main__ - Shuffling the training dataset
10/16/2025 20:46:28 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 20:46:28 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:46:28 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:46:28 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:46:29 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5828778743743896, 'eval_accuracy': 0.352, 'eval_runtime': 3.5301, 'eval_samples_per_second': 566.552, 'eval_steps_per_second': 70.819, 'epoch': 1.0}
{'loss': 1.6047, 'grad_norm': 2.064183473587036, 'learning_rate': 1.2016000000000002e-05, 'epoch': 2.0}
{'eval_loss': 1.578183889389038, 'eval_accuracy': 0.352, 'eval_runtime': 3.5156, 'eval_samples_per_second': 568.889, 'eval_steps_per_second': 71.111, 'epoch': 2.0}
{'eval_loss': 1.5764046907424927, 'eval_accuracy': 0.352, 'eval_runtime': 3.5066, 'eval_samples_per_second': 570.35, 'eval_steps_per_second': 71.294, 'epoch': 3.0}
{'loss': 1.5819, 'grad_norm': 1.11192786693573, 'learning_rate': 4.016e-06, 'epoch': 4.0}
{'eval_loss': 1.5748741626739502, 'eval_accuracy': 0.352, 'eval_runtime': 3.5129, 'eval_samples_per_second': 569.336, 'eval_steps_per_second': 71.167, 'epoch': 4.0}
{'eval_loss': 1.574497938156128, 'eval_accuracy': 0.352, 'eval_runtime': 3.5118, 'eval_samples_per_second': 569.515, 'eval_steps_per_second': 71.189, 'epoch': 5.0}
{'train_runtime': 235.7069, 'train_samples_per_second': 339.405, 'train_steps_per_second': 5.303, 'train_loss': 1.590704150390625, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.5907
  train_runtime            = 0:03:55.70
  train_samples            =      16000
  train_samples_per_second =    339.405
  train_steps_per_second   =      5.303
10/16/2025 20:50:27 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.352
  eval_loss               =     1.5829
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =    574.487
  eval_steps_per_second   =     71.811
10/16/2025 20:50:30 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.3475
  predict_loss               =     1.5644
  predict_runtime            = 0:00:03.47
  predict_samples            =       2000
  predict_samples_per_second =     575.27
  predict_steps_per_second   =     71.909
10/16/2025 20:50:34 - INFO - __main__ - ***** Predict results *****
10/16/2025 20:50:34 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/kocczfys/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mdeft-sweep-2[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/kocczfys[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_204631-kocczfys/logs[0m
10/16/2025 20:50:49 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 20:50:49 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_20-50-48_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 20:50:49 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/k07qncer
10/16/2025 20:50:52 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 20:50:52 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:50:52 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:50:53 - INFO - __main__ - setting problem type to single label classification
10/16/2025 20:50:54 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 20:50:54 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 20:50:54 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 20:50:54 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 20:50:54 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 20:50:55 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 20:50:55 - INFO - __main__ - Shuffling the training dataset
10/16/2025 20:50:55 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 20:50:55 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:50:55 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:50:55 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:50:56 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5829863548278809, 'eval_accuracy': 0.352, 'eval_runtime': 3.5204, 'eval_samples_per_second': 568.113, 'eval_steps_per_second': 71.014, 'epoch': 1.0}
{'loss': 1.6048, 'grad_norm': 2.052785873413086, 'learning_rate': 1.2016000000000002e-05, 'epoch': 2.0}
{'eval_loss': 1.5774641036987305, 'eval_accuracy': 0.352, 'eval_runtime': 3.5146, 'eval_samples_per_second': 569.061, 'eval_steps_per_second': 71.133, 'epoch': 2.0}
{'eval_loss': 1.5755410194396973, 'eval_accuracy': 0.352, 'eval_runtime': 3.5125, 'eval_samples_per_second': 569.402, 'eval_steps_per_second': 71.175, 'epoch': 3.0}
{'loss': 1.5812, 'grad_norm': 1.0984628200531006, 'learning_rate': 4.016e-06, 'epoch': 4.0}
{'eval_loss': 1.5738005638122559, 'eval_accuracy': 0.352, 'eval_runtime': 3.5134, 'eval_samples_per_second': 569.255, 'eval_steps_per_second': 71.157, 'epoch': 4.0}
{'eval_loss': 1.5733040571212769, 'eval_accuracy': 0.352, 'eval_runtime': 3.5111, 'eval_samples_per_second': 569.628, 'eval_steps_per_second': 71.204, 'epoch': 5.0}
{'train_runtime': 235.5144, 'train_samples_per_second': 339.682, 'train_steps_per_second': 5.308, 'train_loss': 1.5903040771484376, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.5903
  train_runtime            = 0:03:55.51
  train_samples            =      16000
  train_samples_per_second =    339.682
  train_steps_per_second   =      5.308
10/16/2025 20:54:54 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.352
  eval_loss               =      1.583
  eval_runtime            = 0:00:03.51
  eval_samples            =       2000
  eval_samples_per_second =    569.112
  eval_steps_per_second   =     71.139
10/16/2025 20:54:57 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.3475
  predict_loss               =     1.5643
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    574.656
  predict_steps_per_second   =     71.832
10/16/2025 20:55:01 - INFO - __main__ - ***** Predict results *****
10/16/2025 20:55:01 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/k07qncer/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mstellar-sweep-3[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/k07qncer[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_205058-k07qncer/logs[0m
10/16/2025 20:55:17 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 20:55:17 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_20-55-16_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 20:55:17 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/xdmp57jn
10/16/2025 20:55:20 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 20:55:20 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:55:20 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:55:21 - INFO - __main__ - setting problem type to single label classification
10/16/2025 20:55:22 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 20:55:22 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 20:55:22 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 20:55:22 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 20:55:22 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 20:55:23 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 20:55:23 - INFO - __main__ - Shuffling the training dataset
10/16/2025 20:55:23 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 20:55:23 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:55:23 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:55:23 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:55:24 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5395910739898682, 'eval_accuracy': 0.514, 'eval_runtime': 3.5248, 'eval_samples_per_second': 567.415, 'eval_steps_per_second': 70.927, 'epoch': 1.0}
{'loss': 1.5354, 'grad_norm': 2.2058441638946533, 'learning_rate': 0.00012016, 'epoch': 2.0}
{'eval_loss': 1.4258675575256348, 'eval_accuracy': 0.524, 'eval_runtime': 3.5235, 'eval_samples_per_second': 567.612, 'eval_steps_per_second': 70.952, 'epoch': 2.0}
{'eval_loss': 1.3367300033569336, 'eval_accuracy': 0.516, 'eval_runtime': 3.5221, 'eval_samples_per_second': 567.836, 'eval_steps_per_second': 70.98, 'epoch': 3.0}
{'loss': 1.3701, 'grad_norm': 1.2991864681243896, 'learning_rate': 4.016e-05, 'epoch': 4.0}
{'eval_loss': 1.2660695314407349, 'eval_accuracy': 0.527, 'eval_runtime': 3.5232, 'eval_samples_per_second': 567.671, 'eval_steps_per_second': 70.959, 'epoch': 4.0}
{'eval_loss': 1.2457331418991089, 'eval_accuracy': 0.53, 'eval_runtime': 3.5083, 'eval_samples_per_second': 570.072, 'eval_steps_per_second': 71.259, 'epoch': 5.0}
{'train_runtime': 235.3474, 'train_samples_per_second': 339.923, 'train_steps_per_second': 5.311, 'train_loss': 1.4250427734375, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =      1.425
  train_runtime            = 0:03:55.34
  train_samples            =      16000
  train_samples_per_second =    339.923
  train_steps_per_second   =      5.311
10/16/2025 20:59:22 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =       0.53
  eval_loss               =     1.2457
  eval_runtime            = 0:00:03.47
  eval_samples            =       2000
  eval_samples_per_second =     575.04
  eval_steps_per_second   =      71.88
10/16/2025 20:59:25 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.534
  predict_loss               =     1.2239
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    573.994
  predict_steps_per_second   =     71.749
10/16/2025 20:59:29 - INFO - __main__ - ***** Predict results *****
10/16/2025 20:59:29 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/xdmp57jn/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mdry-sweep-4[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/xdmp57jn[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_205526-xdmp57jn/logs[0m
10/16/2025 20:59:44 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 20:59:44 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_20-59-43_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 20:59:44 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/ei312lg3
10/16/2025 20:59:47 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 20:59:47 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:59:47 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 20:59:48 - INFO - __main__ - setting problem type to single label classification
10/16/2025 20:59:49 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 20:59:49 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 20:59:49 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 20:59:49 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 20:59:49 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 20:59:50 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 20:59:50 - INFO - __main__ - Shuffling the training dataset
10/16/2025 20:59:50 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 20:59:50 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:59:50 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:59:50 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 20:59:51 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5546021461486816, 'eval_accuracy': 0.4155, 'eval_runtime': 3.5278, 'eval_samples_per_second': 566.923, 'eval_steps_per_second': 70.865, 'epoch': 1.0}
{'loss': 1.55, 'grad_norm': 2.2676494121551514, 'learning_rate': 0.00012016, 'epoch': 2.0}
{'eval_loss': 1.4757492542266846, 'eval_accuracy': 0.494, 'eval_runtime': 3.5094, 'eval_samples_per_second': 569.891, 'eval_steps_per_second': 71.236, 'epoch': 2.0}
{'eval_loss': 1.406774640083313, 'eval_accuracy': 0.523, 'eval_runtime': 3.519, 'eval_samples_per_second': 568.339, 'eval_steps_per_second': 71.042, 'epoch': 3.0}
{'loss': 1.4243, 'grad_norm': 1.4135524034500122, 'learning_rate': 4.016e-05, 'epoch': 4.0}
{'eval_loss': 1.3345690965652466, 'eval_accuracy': 0.5315, 'eval_runtime': 3.5102, 'eval_samples_per_second': 569.77, 'eval_steps_per_second': 71.221, 'epoch': 4.0}
{'eval_loss': 1.3147720098495483, 'eval_accuracy': 0.5285, 'eval_runtime': 3.5032, 'eval_samples_per_second': 570.91, 'eval_steps_per_second': 71.364, 'epoch': 5.0}
{'train_runtime': 235.069, 'train_samples_per_second': 340.326, 'train_steps_per_second': 5.318, 'train_loss': 1.4624843017578124, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.4625
  train_runtime            = 0:03:55.06
  train_samples            =      16000
  train_samples_per_second =    340.326
  train_steps_per_second   =      5.318
10/16/2025 21:03:48 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.5315
  eval_loss               =     1.3346
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =    574.671
  eval_steps_per_second   =     71.834
10/16/2025 21:03:52 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.5365
  predict_loss               =     1.3102
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    574.236
  predict_steps_per_second   =      71.78
10/16/2025 21:03:55 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:03:55 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/ei312lg3/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mcelestial-sweep-5[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/ei312lg3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_205953-ei312lg3/logs[0m
10/16/2025 21:04:10 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:04:10 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.0002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-04-10_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:04:10 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/hg96zfh4
10/16/2025 21:04:14 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:04:14 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:04:14 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:04:14 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:04:15 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:04:15 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:04:15 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:04:15 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:04:15 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:04:16 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:04:16 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:04:16 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:04:16 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:04:16 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:04:16 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:04:18 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.5441139936447144, 'eval_accuracy': 0.493, 'eval_runtime': 3.5166, 'eval_samples_per_second': 568.732, 'eval_steps_per_second': 71.091, 'epoch': 1.0}
{'loss': 1.5443, 'grad_norm': 2.341196060180664, 'learning_rate': 0.00012016, 'epoch': 2.0}
{'eval_loss': 1.4559377431869507, 'eval_accuracy': 0.516, 'eval_runtime': 3.5184, 'eval_samples_per_second': 568.442, 'eval_steps_per_second': 71.055, 'epoch': 2.0}
{'eval_loss': 1.3933683633804321, 'eval_accuracy': 0.5165, 'eval_runtime': 3.5058, 'eval_samples_per_second': 570.482, 'eval_steps_per_second': 71.31, 'epoch': 3.0}
{'loss': 1.4187, 'grad_norm': 1.697201132774353, 'learning_rate': 4.016e-05, 'epoch': 4.0}
{'eval_loss': 1.324834942817688, 'eval_accuracy': 0.5275, 'eval_runtime': 3.5013, 'eval_samples_per_second': 571.214, 'eval_steps_per_second': 71.402, 'epoch': 4.0}
{'eval_loss': 1.3112109899520874, 'eval_accuracy': 0.5275, 'eval_runtime': 3.4982, 'eval_samples_per_second': 571.726, 'eval_steps_per_second': 71.466, 'epoch': 5.0}
{'train_runtime': 235.5161, 'train_samples_per_second': 339.679, 'train_steps_per_second': 5.307, 'train_loss': 1.458786572265625, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.4588
  train_runtime            = 0:03:55.51
  train_samples            =      16000
  train_samples_per_second =    339.679
  train_steps_per_second   =      5.307
10/16/2025 21:08:15 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.5275
  eval_loss               =     1.3248
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =     574.33
  eval_steps_per_second   =     71.791
10/16/2025 21:08:19 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.528
  predict_loss               =     1.3015
  predict_runtime            = 0:00:03.47
  predict_samples            =       2000
  predict_samples_per_second =    575.058
  predict_steps_per_second   =     71.882
10/16/2025 21:08:22 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:08:22 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/hg96zfh4/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mmisunderstood-sweep-6[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/hg96zfh4[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_210419-hg96zfh4/logs[0m
10/16/2025 21:08:37 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:08:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-08-37_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:08:37 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/wfqe0j5s
10/16/2025 21:08:41 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:08:41 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:08:41 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:08:41 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:08:42 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:08:42 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:08:42 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:08:42 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:08:42 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:08:43 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:08:43 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:08:43 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:08:43 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:08:43 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:08:43 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:08:46 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 0.8598742485046387, 'eval_accuracy': 0.696, 'eval_runtime': 3.5235, 'eval_samples_per_second': 567.617, 'eval_steps_per_second': 70.952, 'epoch': 1.0}
{'loss': 1.0891, 'grad_norm': 2.021496295928955, 'learning_rate': 0.0012016, 'epoch': 2.0}
{'eval_loss': 0.6178162693977356, 'eval_accuracy': 0.7865, 'eval_runtime': 3.5062, 'eval_samples_per_second': 570.42, 'eval_steps_per_second': 71.303, 'epoch': 2.0}
{'eval_loss': 0.5166534185409546, 'eval_accuracy': 0.819, 'eval_runtime': 3.5137, 'eval_samples_per_second': 569.208, 'eval_steps_per_second': 71.151, 'epoch': 3.0}
{'loss': 0.6611, 'grad_norm': 1.4166152477264404, 'learning_rate': 0.0004016, 'epoch': 4.0}
{'eval_loss': 0.47750556468963623, 'eval_accuracy': 0.8295, 'eval_runtime': 3.5094, 'eval_samples_per_second': 569.896, 'eval_steps_per_second': 71.237, 'epoch': 4.0}
{'eval_loss': 0.47209441661834717, 'eval_accuracy': 0.8395, 'eval_runtime': 3.5001, 'eval_samples_per_second': 571.409, 'eval_steps_per_second': 71.426, 'epoch': 5.0}
{'train_runtime': 235.8047, 'train_samples_per_second': 339.264, 'train_steps_per_second': 5.301, 'train_loss': 0.8158158081054687, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     0.8158
  train_runtime            = 0:03:55.80
  train_samples            =      16000
  train_samples_per_second =    339.264
  train_steps_per_second   =      5.301
10/16/2025 21:12:43 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8395
  eval_loss               =     0.4721
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =    573.489
  eval_steps_per_second   =     71.686
10/16/2025 21:12:47 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.828
  predict_loss               =     0.4844
  predict_runtime            = 0:00:03.47
  predict_samples            =       2000
  predict_samples_per_second =    575.573
  predict_steps_per_second   =     71.947
10/16/2025 21:12:50 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:12:50 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/wfqe0j5s/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfine-sweep-7[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/wfqe0j5s[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_210847-wfqe0j5s/logs[0m
10/16/2025 21:13:04 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:13:04 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-13-04_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:13:04 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/livpo6rb
10/16/2025 21:13:08 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:13:08 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:13:08 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:13:09 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:13:10 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:13:10 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:13:10 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:13:10 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:13:10 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:13:11 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:13:11 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:13:11 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:13:11 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:13:11 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:13:11 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:13:13 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 0.8367694616317749, 'eval_accuracy': 0.7045, 'eval_runtime': 3.5189, 'eval_samples_per_second': 568.361, 'eval_steps_per_second': 71.045, 'epoch': 1.0}
{'loss': 1.098, 'grad_norm': 1.7378052473068237, 'learning_rate': 0.0012016, 'epoch': 2.0}
{'eval_loss': 0.6362259387969971, 'eval_accuracy': 0.785, 'eval_runtime': 3.5143, 'eval_samples_per_second': 569.106, 'eval_steps_per_second': 71.138, 'epoch': 2.0}
{'eval_loss': 0.5385748147964478, 'eval_accuracy': 0.812, 'eval_runtime': 3.5063, 'eval_samples_per_second': 570.402, 'eval_steps_per_second': 71.3, 'epoch': 3.0}
{'loss': 0.6764, 'grad_norm': 1.4113211631774902, 'learning_rate': 0.0004016, 'epoch': 4.0}
{'eval_loss': 0.4958346486091614, 'eval_accuracy': 0.825, 'eval_runtime': 3.5061, 'eval_samples_per_second': 570.434, 'eval_steps_per_second': 71.304, 'epoch': 4.0}
{'eval_loss': 0.48135682940483093, 'eval_accuracy': 0.835, 'eval_runtime': 3.5117, 'eval_samples_per_second': 569.53, 'eval_steps_per_second': 71.191, 'epoch': 5.0}
{'train_runtime': 235.9898, 'train_samples_per_second': 338.998, 'train_steps_per_second': 5.297, 'train_loss': 0.8300292114257812, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =       0.83
  train_runtime            = 0:03:55.98
  train_samples            =      16000
  train_samples_per_second =    338.998
  train_steps_per_second   =      5.297
10/16/2025 21:17:11 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.835
  eval_loss               =     0.4814
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =    573.773
  eval_steps_per_second   =     71.722
10/16/2025 21:17:14 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.8285
  predict_loss               =     0.4885
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    574.322
  predict_steps_per_second   =      71.79
10/16/2025 21:17:18 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:17:18 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/livpo6rb/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfancy-sweep-8[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/livpo6rb[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_211315-livpo6rb/logs[0m
10/16/2025 21:17:31 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:17:31 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.002,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-17-31_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:17:31 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/2x0us1qt
10/16/2025 21:17:35 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:17:35 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:17:35 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:17:35 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:17:36 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:17:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:17:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:17:36 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:17:36 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:17:38 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:17:38 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:17:38 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:17:38 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:17:38 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:17:38 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:17:41 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 0.781916618347168, 'eval_accuracy': 0.722, 'eval_runtime': 3.5251, 'eval_samples_per_second': 567.361, 'eval_steps_per_second': 70.92, 'epoch': 1.0}
{'loss': 1.0463, 'grad_norm': 1.7304819822311401, 'learning_rate': 0.0012016, 'epoch': 2.0}
{'eval_loss': 0.6208550333976746, 'eval_accuracy': 0.782, 'eval_runtime': 3.5185, 'eval_samples_per_second': 568.422, 'eval_steps_per_second': 71.053, 'epoch': 2.0}
{'eval_loss': 0.5326635837554932, 'eval_accuracy': 0.8115, 'eval_runtime': 3.5119, 'eval_samples_per_second': 569.497, 'eval_steps_per_second': 71.187, 'epoch': 3.0}
{'loss': 0.6469, 'grad_norm': 1.375459909439087, 'learning_rate': 0.0004016, 'epoch': 4.0}
{'eval_loss': 0.4823140799999237, 'eval_accuracy': 0.833, 'eval_runtime': 3.5077, 'eval_samples_per_second': 570.175, 'eval_steps_per_second': 71.272, 'epoch': 4.0}
{'eval_loss': 0.45926305651664734, 'eval_accuracy': 0.8405, 'eval_runtime': 3.5208, 'eval_samples_per_second': 568.055, 'eval_steps_per_second': 71.007, 'epoch': 5.0}
{'train_runtime': 235.1981, 'train_samples_per_second': 340.139, 'train_steps_per_second': 5.315, 'train_loss': 0.790546826171875, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     0.7905
  train_runtime            = 0:03:55.19
  train_samples            =      16000
  train_samples_per_second =    340.139
  train_steps_per_second   =      5.315
10/16/2025 21:21:38 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =     0.8405
  eval_loss               =     0.4593
  eval_runtime            = 0:00:03.49
  eval_samples            =       2000
  eval_samples_per_second =    572.529
  eval_steps_per_second   =     71.566
10/16/2025 21:21:42 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.842
  predict_loss               =     0.4757
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    573.709
  predict_steps_per_second   =     71.714
10/16/2025 21:21:45 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:21:45 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/2x0us1qt/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mcolorful-sweep-9[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/2x0us1qt[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_211743-2x0us1qt/logs[0m
10/16/2025 21:21:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:21:58 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.02,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-21-57_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:21:58 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/5i77kla3
10/16/2025 21:22:02 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:22:02 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:22:02 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:22:03 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:22:04 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:22:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:22:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:22:04 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:22:04 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:22:05 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:22:05 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:22:05 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:22:05 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:22:05 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:22:05 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:22:07 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.4232620000839233, 'eval_accuracy': 0.5795, 'eval_runtime': 3.5164, 'eval_samples_per_second': 568.758, 'eval_steps_per_second': 71.095, 'epoch': 1.0}
{'loss': 1.8021, 'grad_norm': 3.8952219486236572, 'learning_rate': 0.012016, 'epoch': 2.0}
{'eval_loss': 0.7263541221618652, 'eval_accuracy': 0.775, 'eval_runtime': 3.5142, 'eval_samples_per_second': 569.127, 'eval_steps_per_second': 71.141, 'epoch': 2.0}
{'eval_loss': 0.575477123260498, 'eval_accuracy': 0.823, 'eval_runtime': 3.5159, 'eval_samples_per_second': 568.837, 'eval_steps_per_second': 71.105, 'epoch': 3.0}
{'loss': 0.7962, 'grad_norm': 3.238449811935425, 'learning_rate': 0.0040160000000000005, 'epoch': 4.0}
{'eval_loss': 0.38845691084861755, 'eval_accuracy': 0.8775, 'eval_runtime': 3.5097, 'eval_samples_per_second': 569.855, 'eval_steps_per_second': 71.232, 'epoch': 4.0}
{'eval_loss': 0.33183735609054565, 'eval_accuracy': 0.887, 'eval_runtime': 3.5093, 'eval_samples_per_second': 569.919, 'eval_steps_per_second': 71.24, 'epoch': 5.0}
{'train_runtime': 235.3362, 'train_samples_per_second': 339.939, 'train_steps_per_second': 5.312, 'train_loss': 1.1420273315429688, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =      1.142
  train_runtime            = 0:03:55.33
  train_samples            =      16000
  train_samples_per_second =    339.939
  train_steps_per_second   =      5.312
10/16/2025 21:26:04 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.887
  eval_loss               =     0.3318
  eval_runtime            = 0:00:03.47
  eval_samples            =       2000
  eval_samples_per_second =    574.912
  eval_steps_per_second   =     71.864
10/16/2025 21:26:08 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.876
  predict_loss               =     0.3385
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =      574.3
  predict_steps_per_second   =     71.787
10/16/2025 21:26:11 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:26:11 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/5i77kla3/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mfancy-sweep-10[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/5i77kla3[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_212209-5i77kla3/logs[0m
10/16/2025 21:26:45 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:26:45 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.02,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-26-44_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:26:45 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/8pojaf9j
10/16/2025 21:26:48 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:26:48 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:26:48 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:26:48 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:26:50 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:26:50 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:26:50 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:26:50 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:26:50 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:26:51 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:26:51 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:26:51 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:26:51 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:26:51 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:26:51 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:26:52 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.9789457321166992, 'eval_accuracy': 0.459, 'eval_runtime': 3.5247, 'eval_samples_per_second': 567.416, 'eval_steps_per_second': 70.927, 'epoch': 1.0}
{'loss': 2.2238, 'grad_norm': 7.202974319458008, 'learning_rate': 0.012016, 'epoch': 2.0}
{'eval_loss': 1.4710965156555176, 'eval_accuracy': 0.531, 'eval_runtime': 3.5184, 'eval_samples_per_second': 568.447, 'eval_steps_per_second': 71.056, 'epoch': 2.0}
{'eval_loss': 1.2981579303741455, 'eval_accuracy': 0.6085, 'eval_runtime': 3.5181, 'eval_samples_per_second': 568.489, 'eval_steps_per_second': 71.061, 'epoch': 3.0}
{'loss': 1.2518, 'grad_norm': 3.479203462600708, 'learning_rate': 0.0040160000000000005, 'epoch': 4.0}
{'eval_loss': 0.7168223261833191, 'eval_accuracy': 0.7445, 'eval_runtime': 3.5175, 'eval_samples_per_second': 568.591, 'eval_steps_per_second': 71.074, 'epoch': 4.0}
{'eval_loss': 0.6117206811904907, 'eval_accuracy': 0.77, 'eval_runtime': 3.5102, 'eval_samples_per_second': 569.765, 'eval_steps_per_second': 71.221, 'epoch': 5.0}
{'train_runtime': 235.1587, 'train_samples_per_second': 340.196, 'train_steps_per_second': 5.316, 'train_loss': 1.55301416015625, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =      1.553
  train_runtime            = 0:03:55.15
  train_samples            =      16000
  train_samples_per_second =    340.196
  train_steps_per_second   =      5.316
10/16/2025 21:30:49 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =       0.77
  eval_loss               =     0.6117
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =     574.35
  eval_steps_per_second   =     71.794
10/16/2025 21:30:53 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =      0.768
  predict_loss               =     0.6101
  predict_runtime            = 0:00:03.47
  predict_samples            =       2000
  predict_samples_per_second =    575.092
  predict_steps_per_second   =     71.887
10/16/2025 21:30:56 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:30:56 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/8pojaf9j/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33mprime-sweep-11[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/8pojaf9j[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_212654-8pojaf9j/logs[0m
10/16/2025 21:31:12 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
10/16/2025 21:31:12 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
average_tokens_across_devices=True,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=no,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.02,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=./prompt_tuning_soft_outputs/runs/Oct16_21-31-12_xgpi0,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=500,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=5.0,
optim=OptimizerNames.ADAMW_TORCH_FUSED,
optim_args=None,
optim_target_modules=None,
output_dir=./prompt_tuning_soft_outputs,
overwrite_output_dir=False,
parallelism_config=None,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
project=huggingface,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['wandb'],
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
run_name=None,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
seed=23,
skip_memory_metrics=True,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trackio_space_id=trackio,
use_cpu=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
10/16/2025 21:31:12 - INFO - __main__ - W&B run detected. Setting output directory to: ./prompt_tuning_soft_outputs/tz42gcm2
10/16/2025 21:31:16 - INFO - datasets.builder - Found cached dataset emotion (/home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe)
10/16/2025 21:31:16 - INFO - __main__ - Dataset loaded: DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:31:16 - INFO - __main__ - DatasetDict({
    train: Dataset({
        features: ['text', 'label'],
        num_rows: 16000
    })
    validation: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
    test: Dataset({
        features: ['text', 'label'],
        num_rows: 2000
    })
})
10/16/2025 21:31:16 - INFO - __main__ - setting problem type to single label classification
10/16/2025 21:31:17 - WARNING - __main__ - The label2id key in the model config.json is not equal to the label2id key of this run. You can ignore this if you are doing finetuning.
10/16/2025 21:31:17 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-b8ac2428a1057bd7_*_of_00001.arrow
10/16/2025 21:31:17 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-721393e362c2a5f2_*_of_00001.arrow
10/16/2025 21:31:17 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-6504e3b82624e895_*_of_00001.arrow
10/16/2025 21:31:17 - INFO - __main__ - PEFT method prompt_tuning is specified, applying PEFT now
10/16/2025 21:31:18 - INFO - __main__ - PEFT model created.
trainable params: 610,566 || all params: 125,260,812 || trainable%: 0.4874
10/16/2025 21:31:18 - INFO - __main__ - Shuffling the training dataset
10/16/2025 21:31:18 - INFO - datasets.arrow_dataset - Loading cached shuffled indices for dataset at /home/e/e0969050/.cache/huggingface/datasets/dair-ai___emotion/split/0.0.0/cab853a1dbdf4c42c2b3ef2173804746df8825fe/cache-817b0581e49fdde8.arrow
10/16/2025 21:31:18 - INFO - __main__ - Sample 15152 of the training set: {'text': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'label': 2, 'sentence': 'i was already feeling loved for having been asked to be in the bridal party the thank you note made me feel even more so', 'input_ids': [0, 118, 21, 416, 2157, 2638, 13, 519, 57, 553, 7, 28, 11, 5, 5378, 11934, 537, 5, 3392, 47, 1591, 156, 162, 619, 190, 55, 98, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:31:18 - INFO - __main__ - Sample 12769 of the training set: {'text': 'i have always wanted ice cream when i feel lousy', 'label': 0, 'sentence': 'i have always wanted ice cream when i feel lousy', 'input_ids': [0, 118, 33, 460, 770, 2480, 6353, 77, 939, 619, 38909, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:31:18 - INFO - __main__ - Sample 15541 of the training set: {'text': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'label': 5, 'sentence': 'i start to remember how desperately i felt when trying to get pregnant after feeling impressed to start having a family and soon finding that its not as easy as you think to just get pregnant', 'input_ids': [0, 118, 386, 7, 2145, 141, 12420, 939, 1299, 77, 667, 7, 120, 5283, 71, 2157, 6889, 7, 386, 519, 10, 284, 8, 1010, 2609, 14, 63, 45, 25, 1365, 25, 47, 206, 7, 95, 120, 5283, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
10/16/2025 21:31:20 - INFO - __main__ - Using metric accuracy for evaluation.
{'eval_loss': 1.6154342889785767, 'eval_accuracy': 0.466, 'eval_runtime': 3.5209, 'eval_samples_per_second': 568.032, 'eval_steps_per_second': 71.004, 'epoch': 1.0}
{'loss': 1.9338, 'grad_norm': 7.749736309051514, 'learning_rate': 0.012016, 'epoch': 2.0}
{'eval_loss': 1.2067182064056396, 'eval_accuracy': 0.649, 'eval_runtime': 3.5213, 'eval_samples_per_second': 567.973, 'eval_steps_per_second': 70.997, 'epoch': 2.0}
{'eval_loss': 0.9072999358177185, 'eval_accuracy': 0.72, 'eval_runtime': 3.5152, 'eval_samples_per_second': 568.962, 'eval_steps_per_second': 71.12, 'epoch': 3.0}
{'loss': 0.9277, 'grad_norm': 2.0553133487701416, 'learning_rate': 0.0040160000000000005, 'epoch': 4.0}
{'eval_loss': 0.461585134267807, 'eval_accuracy': 0.835, 'eval_runtime': 3.5238, 'eval_samples_per_second': 567.572, 'eval_steps_per_second': 70.947, 'epoch': 4.0}
{'eval_loss': 0.3950253427028656, 'eval_accuracy': 0.855, 'eval_runtime': 3.5206, 'eval_samples_per_second': 568.092, 'eval_steps_per_second': 71.011, 'epoch': 5.0}
{'train_runtime': 234.9933, 'train_samples_per_second': 340.435, 'train_steps_per_second': 5.319, 'train_loss': 1.2669168579101562, 'epoch': 5.0}
***** train metrics *****
  epoch                    =        5.0
  total_flos               =  4935059GF
  train_loss               =     1.2669
  train_runtime            = 0:03:54.99
  train_samples            =      16000
  train_samples_per_second =    340.435
  train_steps_per_second   =      5.319
10/16/2025 21:35:16 - INFO - __main__ - *** Evaluate ***
***** eval metrics *****
  epoch                   =        5.0
  eval_accuracy           =      0.855
  eval_loss               =      0.395
  eval_runtime            = 0:00:03.48
  eval_samples            =       2000
  eval_samples_per_second =    573.766
  eval_steps_per_second   =     71.721
10/16/2025 21:35:19 - INFO - __main__ - *** Predict ***
***** predict metrics *****
  predict_accuracy           =     0.8475
  predict_loss               =     0.4141
  predict_runtime            = 0:00:03.48
  predict_samples            =       2000
  predict_samples_per_second =    573.569
  predict_steps_per_second   =     71.696
10/16/2025 21:35:23 - INFO - __main__ - ***** Predict results *****
10/16/2025 21:35:23 - INFO - __main__ - Predict results saved at ./prompt_tuning_soft_outputs/tz42gcm2/predict_results.txt
[1;34mwandb[0m: 
[1;34mwandb[0m: ðŸš€ View run [33msilver-sweep-12[0m at: [34mhttps://wandb.ai/ncduy0303/dsa4213-assignment-3/runs/tz42gcm2[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251016_213121-tz42gcm2/logs[0m
